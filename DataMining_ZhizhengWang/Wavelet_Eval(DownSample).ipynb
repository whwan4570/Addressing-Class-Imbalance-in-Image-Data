{"cells":[{"cell_type":"markdown","source":["## Wavelet Resampling\n","### Author: Zhizheng Wang"],"metadata":{"id":"ZAZhmeJcU2B3"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":25482,"status":"ok","timestamp":1731987297037,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"a1c-aHdTJ75e","outputId":"74f61c29-2947-474f-bce0-4456e4528307"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import pandas as pd\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"markdown","source":["# Downsample"],"metadata":{"id":"93HLCurOT9MX"}},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2681,"status":"ok","timestamp":1731987305470,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"-pzylNewV18o","outputId":"1b482268-9fe0-4b76-9dc0-fce18cccb1fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (4046, 2)\n","Test shape: (2056, 1)\n"]}],"source":["# Define file paths\n","train_csv = \"/content/drive/MyDrive/Colab_Notebooks/dataset/train_downsampled.csv\"\n","test_csv = \"/content/drive/MyDrive/Colab_Notebooks/dataset/test.csv\"\n","\n","# Load CSV files\n","train = pd.read_csv(train_csv, usecols=[\"image_ID\", \"label\"])\n","test = pd.read_csv(test_csv, usecols=[\"image_ID\"])\n","\n","# Display shapes of train and test datasets\n","print(\"Train shape:\", train.shape)\n","print(\"Test shape:\", test.shape)\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":354,"status":"ok","timestamp":1731987307466,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"FY0mGQ6w0j_k","outputId":"2479315a-1914-4f70-b47f-3724a3cf1076"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unique classes: ['Swimming' 'Badminton' 'Wrestling' 'Cricket' 'Soccer' 'Karate' 'Tennis']\n","Number of unique classes: 7\n"]}],"source":["image_to_label_map = dict(zip(train[\"image_ID\"].values, train[\"label\"].values))\n","\n","unique_classes = train[\"label\"].unique()\n","print(\"Unique classes:\", unique_classes)\n","print(\"Number of unique classes:\", len(unique_classes))"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":468},"executionInfo":{"elapsed":2077,"status":"ok","timestamp":1731987311105,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"ezsDzhbj0pPw","outputId":"9868f0e9-2ba6-424a-caac-35c73cab7475"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Axes: xlabel='label', ylabel='count'>"]},"metadata":{},"execution_count":4},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["import seaborn as sns\n","\n","sns.countplot(data=train, x=\"label\")"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":342,"status":"ok","timestamp":1731987381419,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"7xKIaF8j0sM_","outputId":"14c54260-76b0-44ee-bf38-d97e3ae12a75"},"outputs":[{"output_type":"stream","name":"stdout","text":["label\n","Swimming     578\n","Badminton    578\n","Wrestling    578\n","Cricket      578\n","Soccer       578\n","Karate       578\n","Tennis       578\n","Name: count, dtype: int64\n"]}],"source":["label_counts = train[\"label\"].value_counts()\n","print(label_counts)"]},{"cell_type":"markdown","metadata":{"id":"mIXOswvxJ8aI"},"source":["## Resnet50"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"7cWYAht4DoDq","executionInfo":{"status":"ok","timestamp":1731987392322,"user_tz":300,"elapsed":7798,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"}}},"outputs":[],"source":["from PIL import Image\n","import os\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import models, transforms\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.model_selection import train_test_split\n","from torch.cuda.amp import GradScaler, autocast\n","from torch.amp import GradScaler, autocast\n","from tqdm import tqdm\n","\n","# Resnet50\n","# Dataset class for loading images and labels\n","class CustomImageDataset(Dataset):\n","    def __init__(self, dataframe, img_dir, transform=None, is_test=False):\n","        self.dataframe = dataframe\n","        self.img_dir = img_dir\n","        self.transform = transform\n","        self.is_test = is_test\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","        img_name = os.path.join(self.img_dir, self.dataframe.iloc[idx, 0])\n","        image = Image.open(img_name).convert(\"RGB\")\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        if self.is_test or \"label\" not in self.dataframe.columns:\n","            return image  # No label available for test data\n","        label = torch.tensor(self.dataframe.iloc[idx, 1], dtype=torch.long)\n","        return image, label\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1416,"status":"ok","timestamp":1731987401915,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"zOzxyzhX0sPo","outputId":"9c72bfb6-4e8e-4be3-f936-edcf8a2ba9c8"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100%|██████████| 97.8M/97.8M [00:00<00:00, 223MB/s]\n"]}],"source":["# 2. Split Data into Train and Validation Sets\n","train['label'] = pd.Categorical(train['label']).codes\n","train_df, val_df = train_test_split(train, test_size=0.2, random_state=42)  # 80-20 split\n","\n","# 3. Define Image Transformations\n","transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","# 4. Define Image Directory Paths\n","train_img_dir = \"/content/drive/MyDrive/Colab_Notebooks/dataset/downsampled/\"\n","test_img_dir = \"/content/drive/MyDrive/Colab_Notebooks/dataset/test/\"\n","\n","# 5. Create Datasets and Dataloaders\n","train_dataset = CustomImageDataset(train_df, train_img_dir, transform=transform)\n","val_dataset = CustomImageDataset(val_df, train_img_dir, transform=transform)  # Same dir if validation images are in `train`\n","test_dataset = CustomImageDataset(test, test_img_dir, transform=transform, is_test=True)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n","\n","# 6. Model Setup\n","num_classes = len(train[\"label\"].unique())\n","model = models.resnet50(pretrained=True)\n","model.fc = nn.Linear(model.fc.in_features, num_classes)  # Adjusting last layer\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# 7. Loss Function, Optimizer, and Scheduler\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39754,"status":"ok","timestamp":1731988299780,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"BbAEmm2J0sSV","outputId":"0a370b72-d311-4acf-dc7b-3ee6755d628f"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Start training...\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 1/5 - Training: 100%|██████████| 102/102 [11:20<00:00,  6.67s/it]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch [1/5], Training Loss: 1.5451, Training Accuracy: 0.4456\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/5 - Validation: 100%|██████████| 26/26 [02:57<00:00,  6.84s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/5], Validation Loss: 1.8910, Validation Accuracy: 0.4630\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/5 - Training: 100%|██████████| 102/102 [00:07<00:00, 13.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/5], Training Loss: 1.1961, Training Accuracy: 0.5742\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/5 - Validation: 100%|██████████| 26/26 [00:01<00:00, 13.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/5], Validation Loss: 1.1745, Validation Accuracy: 0.5889\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/5 - Training: 100%|██████████| 102/102 [00:07<00:00, 14.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/5], Training Loss: 1.0199, Training Accuracy: 0.6409\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/5 - Validation: 100%|██████████| 26/26 [00:02<00:00, 12.84it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/5], Validation Loss: 1.1752, Validation Accuracy: 0.6062\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/5 - Training: 100%|██████████| 102/102 [00:07<00:00, 13.88it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/5], Training Loss: 0.8386, Training Accuracy: 0.7142\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/5 - Validation: 100%|██████████| 26/26 [00:01<00:00, 13.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/5], Validation Loss: 1.3309, Validation Accuracy: 0.5370\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/5 - Training: 100%|██████████| 102/102 [00:07<00:00, 13.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/5], Training Loss: 0.7420, Training Accuracy: 0.7420\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/5 - Validation: 100%|██████████| 26/26 [00:01<00:00, 13.40it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/5], Validation Loss: 1.2840, Validation Accuracy: 0.5926\n","Training completed.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# Initialize GradScaler with updated syntax\n","scaler = GradScaler()\n","\n","num_epochs = 5  # Set number of epochs\n","\n","# Initialize lists to store metrics for each epoch\n","train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n","\n","print(\"Start training...\")\n","\n","for epoch in range(num_epochs):\n","    # Training phase\n","    model.train()\n","    running_loss, correct, total = 0.0, 0, 0\n","    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        with autocast(device_type=device.type):\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        running_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs, 1)\n","        correct += (predicted == labels).sum().item()\n","        total += labels.size(0)\n","\n","    # Calculate accuracy and loss for the training epoch\n","    train_loss = running_loss / total\n","    train_accuracy = correct / total\n","    train_losses.append(train_loss)\n","    train_accuracies.append(train_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n","\n","    # Validation phase\n","    model.eval()\n","    val_running_loss, val_correct, val_total = 0.0, 0, 0\n","    with torch.no_grad():\n","        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            val_running_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs, 1)\n","            val_correct += (predicted == labels).sum().item()\n","            val_total += labels.size(0)\n","\n","    # Calculate accuracy and loss for the validation epoch\n","    val_loss = val_running_loss / val_total\n","    val_accuracy = val_correct / val_total\n","    val_losses.append(val_loss)\n","    val_accuracies.append(val_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n","\n","    # Step the learning rate scheduler\n","    scheduler.step()\n","\n","    # Save model if it improves\n","    if val_accuracy > max(val_accuracies, default=0):\n","        torch.save(model.state_dict(), f\"saved_models/sports_best_model.pth\")\n","        print(\"Model saved!\")\n","\n","# End of training\n","print(\"Training completed.\")"]},{"cell_type":"markdown","metadata":{"id":"Hg66Rpx3pbmq"},"source":["Epoch [5/5], Training Loss: 0.3478, Training Accuracy: 0.8865\n"]},{"cell_type":"markdown","metadata":{"id":"nvCQhqfBI2SJ"},"source":["## VGG"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52182,"status":"ok","timestamp":1731988455343,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"yzO67DiapXms","outputId":"905f99ac-fdda-4cd8-e4be-89f4677145ea"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n","100%|██████████| 528M/528M [00:02<00:00, 231MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Start training with VGG16...\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/5 - Training: 100%|██████████| 102/102 [00:07<00:00, 13.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/5], Training Loss: 2.2752, Training Accuracy: 0.1465\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/5 - Validation: 100%|██████████| 26/26 [00:03<00:00,  8.18it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/5], Validation Loss: 1.9573, Validation Accuracy: 0.1346\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/5 - Training: 100%|██████████| 102/102 [00:07<00:00, 14.04it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/5], Training Loss: 1.9557, Training Accuracy: 0.1456\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/5 - Validation: 100%|██████████| 26/26 [00:01<00:00, 13.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/5], Validation Loss: 1.9498, Validation Accuracy: 0.1444\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/5 - Training: 100%|██████████| 102/102 [00:07<00:00, 13.97it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/5], Training Loss: 2.0503, Training Accuracy: 0.1363\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/5 - Validation: 100%|██████████| 26/26 [00:01<00:00, 13.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/5], Validation Loss: 1.9577, Validation Accuracy: 0.1444\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/5 - Training: 100%|██████████| 102/102 [00:07<00:00, 13.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/5], Training Loss: 1.9539, Training Accuracy: 0.1372\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/5 - Validation: 100%|██████████| 26/26 [00:01<00:00, 14.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/5], Validation Loss: 1.9470, Validation Accuracy: 0.1444\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/5 - Training: 100%|██████████| 102/102 [00:07<00:00, 13.91it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/5], Training Loss: 1.9524, Training Accuracy: 0.1452\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/5 - Validation: 100%|██████████| 26/26 [00:02<00:00, 12.95it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/5], Validation Loss: 1.9458, Validation Accuracy: 0.1444\n","Training with VGG16 completed.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# VGG\n","\n","num_classes = len(train[\"label\"].unique())\n","\n","# Load VGG16 with pre-trained weights and modify the classifier layer\n","model = models.vgg16(pretrained=True)\n","model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)  # Adjust the final layer\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# 7. Define Loss Function, Optimizer, and Scheduler\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","\n","# Initialize GradScaler for mixed precision training\n","scaler = GradScaler()\n","\n","num_epochs = 5  # Set the number of epochs\n","train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n","\n","print(\"Start training with VGG16...\")\n","\n","# 8. Training Loop\n","for epoch in range(num_epochs):\n","    # Training phase\n","    model.train()\n","    running_loss, correct, total = 0.0, 0, 0\n","    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        with autocast(device_type=device.type):\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        running_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs, 1)\n","        correct += (predicted == labels).sum().item()\n","        total += labels.size(0)\n","\n","    train_loss = running_loss / total\n","    train_accuracy = correct / total\n","    train_losses.append(train_loss)\n","    train_accuracies.append(train_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n","\n","    # Validation phase\n","    model.eval()\n","    val_running_loss, val_correct, val_total = 0.0, 0, 0\n","    with torch.no_grad():\n","        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            val_running_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs, 1)\n","            val_correct += (predicted == labels).sum().item()\n","            val_total += labels.size(0)\n","\n","    val_loss = val_running_loss / val_total\n","    val_accuracy = val_correct / val_total\n","    val_losses.append(val_loss)\n","    val_accuracies.append(val_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n","\n","    # Step the learning rate scheduler\n","    scheduler.step()\n","\n","    # Save model if it improves\n","    if val_accuracy > max(val_accuracies, default=0):\n","        torch.save(model.state_dict(), f\"saved_models/sports_best_vgg16_model.pth\")\n","        print(\"Model saved!\")\n","\n","print(\"Training with VGG16 completed.\")"]},{"cell_type":"markdown","metadata":{"id":"oNFbW1VWJLqM"},"source":["## GoogleNet"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48239,"status":"ok","timestamp":1731988503577,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"Xom_qLVhqg4E","outputId":"c9ca24d4-ec2c-4119-872d-a5c1c659b437"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n","100%|██████████| 49.7M/49.7M [00:00<00:00, 206MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Start training with GoogLeNet...\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/5 - Training: 100%|██████████| 102/102 [00:07<00:00, 13.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/5], Training Loss: 1.0159, Training Accuracy: 0.6554\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/5 - Validation: 100%|██████████| 26/26 [00:01<00:00, 13.24it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/5], Validation Loss: 0.8680, Validation Accuracy: 0.6926\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/5 - Training: 100%|██████████| 102/102 [00:07<00:00, 13.54it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/5], Training Loss: 0.6137, Training Accuracy: 0.7880\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/5 - Validation: 100%|██████████| 26/26 [00:01<00:00, 13.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/5], Validation Loss: 1.0649, Validation Accuracy: 0.6716\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/5 - Training: 100%|██████████| 102/102 [00:07<00:00, 13.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/5], Training Loss: 0.4605, Training Accuracy: 0.8473\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/5 - Validation: 100%|██████████| 26/26 [00:01<00:00, 13.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/5], Validation Loss: 0.5891, Validation Accuracy: 0.8284\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/5 - Training: 100%|██████████| 102/102 [00:07<00:00, 14.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/5], Training Loss: 0.2749, Training Accuracy: 0.9098\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/5 - Validation: 100%|██████████| 26/26 [00:01<00:00, 13.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/5], Validation Loss: 0.7284, Validation Accuracy: 0.7827\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/5 - Training: 100%|██████████| 102/102 [00:07<00:00, 13.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/5], Training Loss: 0.4455, Training Accuracy: 0.8548\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/5 - Validation: 100%|██████████| 26/26 [00:01<00:00, 13.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/5], Validation Loss: 0.7400, Validation Accuracy: 0.8074\n","Training with GoogLeNet completed.\n"]}],"source":["num_classes = len(train[\"label\"].unique())\n","\n","# Load GoogLeNet with pre-trained weights and modify the final layer\n","model = models.googlenet(pretrained=True)\n","model.fc = nn.Linear(model.fc.in_features, num_classes)  # Adjust final fully connected layer\n","\n","# Move model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# Define loss function, optimizer, and scheduler\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","scaler = GradScaler()  # Mixed precision training\n","\n","# Training loop remains the same as in your existing code\n","num_epochs = 5\n","train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n","\n","print(\"Start training with GoogLeNet...\")\n","\n","for epoch in range(num_epochs):\n","    # Training phase\n","    model.train()\n","    running_loss, correct, total = 0.0, 0, 0\n","    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        with autocast(device_type=device.type):\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        running_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs, 1)\n","        correct += (predicted == labels).sum().item()\n","        total += labels.size(0)\n","\n","    train_loss = running_loss / total\n","    train_accuracy = correct / total\n","    train_losses.append(train_loss)\n","    train_accuracies.append(train_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n","\n","    # Validation phase\n","    model.eval()\n","    val_running_loss, val_correct, val_total = 0.0, 0, 0\n","    with torch.no_grad():\n","        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            val_running_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs, 1)\n","            val_correct += (predicted == labels).sum().item()\n","            val_total += labels.size(0)\n","\n","    val_loss = val_running_loss / val_total\n","    val_accuracy = val_correct / val_total\n","    val_losses.append(val_loss)\n","    val_accuracies.append(val_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n","\n","    # Step the learning rate scheduler\n","    scheduler.step()\n","\n","    # Save model if it improves\n","    if val_accuracy > max(val_accuracies, default=0):\n","        torch.save(model.state_dict(), f\"saved_models/sports_best_googlenet_model.pth\")\n","        print(\"Model saved!\")\n","\n","print(\"Training with GoogLeNet completed.\")"]},{"cell_type":"markdown","metadata":{"id":"zoPTVfsPIvw0"},"source":["## AlexNet"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47107,"status":"ok","timestamp":1731988550678,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"VrdTkc3pqg7j","outputId":"63aceacf-0613-442e-cac2-0f98514339b4"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n","100%|██████████| 233M/233M [00:01<00:00, 231MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Start training with AlexNet...\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/5 - Training: 100%|██████████| 102/102 [00:07<00:00, 14.21it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/5], Training Loss: 2.1184, Training Accuracy: 0.1425\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/5 - Validation: 100%|██████████| 26/26 [00:01<00:00, 14.14it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/5], Validation Loss: 1.9505, Validation Accuracy: 0.1358\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/5 - Training: 100%|██████████| 102/102 [00:07<00:00, 14.25it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/5], Training Loss: 1.9497, Training Accuracy: 0.1409\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/5 - Validation: 100%|██████████| 26/26 [00:01<00:00, 13.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/5], Validation Loss: 1.9480, Validation Accuracy: 0.1358\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/5 - Training: 100%|██████████| 102/102 [00:06<00:00, 14.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/5], Training Loss: 1.9475, Training Accuracy: 0.1400\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/5 - Validation: 100%|██████████| 26/26 [00:02<00:00, 12.93it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/5], Validation Loss: 1.9474, Validation Accuracy: 0.1444\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/5 - Training: 100%|██████████| 102/102 [00:07<00:00, 13.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/5], Training Loss: 1.9470, Training Accuracy: 0.1347\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/5 - Validation: 100%|██████████| 26/26 [00:01<00:00, 14.16it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/5], Validation Loss: 1.9476, Validation Accuracy: 0.1346\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/5 - Training: 100%|██████████| 102/102 [00:07<00:00, 14.22it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/5], Training Loss: 1.9472, Training Accuracy: 0.1292\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/5 - Validation: 100%|██████████| 26/26 [00:01<00:00, 13.73it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/5], Validation Loss: 1.9475, Validation Accuracy: 0.1346\n","Training with AlexNet completed.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# AlexNet\n","\n","# Set the number of classes for the final layer\n","num_classes = len(train[\"label\"].unique())\n","\n","# Load AlexNet with pre-trained weights and adjust the classifier for the number of classes\n","model = models.alexnet(pretrained=True)\n","model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)  # Modify final fully connected layer\n","\n","# Move model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# Define loss function, optimizer, and scheduler\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","scaler = GradScaler()  # For mixed precision training\n","\n","# Initialize lists to store metrics\n","num_epochs = 5\n","train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n","\n","print(\"Start training with AlexNet...\")\n","\n","for epoch in range(num_epochs):\n","    # Training phase\n","    model.train()\n","    running_loss, correct, total = 0.0, 0, 0\n","    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        with autocast(device_type=device.type):\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        running_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs, 1)\n","        correct += (predicted == labels).sum().item()\n","        total += labels.size(0)\n","\n","    # Calculate accuracy and loss for the training epoch\n","    train_loss = running_loss / total\n","    train_accuracy = correct / total\n","    train_losses.append(train_loss)\n","    train_accuracies.append(train_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n","\n","    # Validation phase\n","    model.eval()\n","    val_running_loss, val_correct, val_total = 0.0, 0, 0\n","    with torch.no_grad():\n","        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            val_running_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs, 1)\n","            val_correct += (predicted == labels).sum().item()\n","            val_total += labels.size(0)\n","\n","    val_loss = val_running_loss / val_total\n","    val_accuracy = val_correct / val_total\n","    val_losses.append(val_loss)\n","    val_accuracies.append(val_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n","\n","    # Step the learning rate scheduler\n","    scheduler.step()\n","\n","    # Save model if it improves\n","    if val_accuracy > max(val_accuracies, default=0):\n","        torch.save(model.state_dict(), f\"saved_models/sports_best_alexnet_model.pth\")\n","        print(\"Model saved!\")\n","\n","print(\"Training with AlexNet completed.\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}