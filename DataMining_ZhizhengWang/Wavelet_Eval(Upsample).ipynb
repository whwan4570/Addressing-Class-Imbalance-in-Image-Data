{"cells":[{"cell_type":"markdown","source":["## Wavelet Resampling\n","### Author: Zhizheng Wang"],"metadata":{"id":"1HL0T1xTlKwn"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":17348,"status":"ok","timestamp":1731991197000,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"a1c-aHdTJ75e","outputId":"7cff8982-4356-43ad-de64-dc0e92ebc48b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import pandas as pd\n","from google.colab import drive\n","\n","# Mount Google Drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":289,"status":"ok","timestamp":1731877869026,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"-pzylNewV18o","outputId":"5bb0a1ce-b107-4b22-b576-6691497d83b1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train shape: (8227, 2)\n","Test shape: (2056, 1)\n"]}],"source":["# Define file paths\n","train_csv = \"/content/drive/MyDrive/Colab_Notebooks/dataset/train.csv\"\n","test_csv = \"/content/drive/MyDrive/Colab_Notebooks/dataset/test.csv\"\n","\n","# Load CSV files\n","train = pd.read_csv(train_csv, usecols=[\"image_ID\", \"label\"])\n","test = pd.read_csv(test_csv, usecols=[\"image_ID\"])\n","\n","# Display shapes of train and test datasets\n","print(\"Train shape:\", train.shape)\n","print(\"Test shape:\", test.shape)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1021,"status":"ok","timestamp":1731877633121,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"FY0mGQ6w0j_k","outputId":"ce23b01f-9b96-4d43-b4e7-0d5cff33ffae"},"outputs":[{"name":"stdout","output_type":"stream","text":["Unique classes: ['Badminton' 'Cricket' 'Tennis' 'Swimming' 'Soccer' 'Wrestling' 'Karate']\n","Number of unique classes: 7\n"]}],"source":["image_to_label_map = dict(zip(train[\"image_ID\"].values, train[\"label\"].values))\n","\n","unique_classes = train[\"label\"].unique()\n","print(\"Unique classes:\", unique_classes)\n","print(\"Number of unique classes:\", len(unique_classes))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":466},"executionInfo":{"elapsed":586,"status":"ok","timestamp":1731877873058,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"ezsDzhbj0pPw","outputId":"a96feaa8-1799-4510-f247-53cad7ba4bd1"},"outputs":[{"data":{"text/plain":["<Axes: xlabel='label', ylabel='count'>"]},"execution_count":22,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import seaborn as sns\n","\n","sns.countplot(data=train, x=\"label\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":793,"status":"ok","timestamp":1731877875698,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"7xKIaF8j0sM_","outputId":"065447d3-1cf8-44e8-e9f9-56c1e5e6a9f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["label\n","Cricket      1556\n","Wrestling    1471\n","Tennis       1445\n","Badminton    1394\n","Soccer       1188\n","Swimming      595\n","Karate        578\n","Name: count, dtype: int64\n"]}],"source":["label_counts = train[\"label\"].value_counts()\n","print(label_counts)"]},{"cell_type":"markdown","metadata":{"id":"mIXOswvxJ8aI"},"source":["## Resnet50"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7cWYAht4DoDq"},"outputs":[],"source":["from PIL import Image\n","import os\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import models, transforms\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.model_selection import train_test_split\n","from torch.cuda.amp import GradScaler, autocast\n","from torch.amp import GradScaler, autocast\n","from tqdm import tqdm\n","\n","# Resnet50\n","# Dataset class for loading images and labels\n","class CustomImageDataset(Dataset):\n","    def __init__(self, dataframe, img_dir, transform=None, is_test=False):\n","        self.dataframe = dataframe\n","        self.img_dir = img_dir\n","        self.transform = transform\n","        self.is_test = is_test\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","        img_name = os.path.join(self.img_dir, self.dataframe.iloc[idx, 0])\n","        image = Image.open(img_name).convert(\"RGB\")\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        if self.is_test or \"label\" not in self.dataframe.columns:\n","            return image  # No label available for test data\n","        label = torch.tensor(self.dataframe.iloc[idx, 1], dtype=torch.long)\n","        return image, label\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":570,"status":"ok","timestamp":1731877882029,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"zOzxyzhX0sPo","outputId":"14656f19-fc20-43be-ef5d-08f160f0ef63"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["# 2. Split Data into Train and Validation Sets\n","train['label'] = pd.Categorical(train['label']).codes\n","train_df, val_df = train_test_split(train, test_size=0.2, random_state=42)  # 80-20 split\n","\n","# 3. Define Image Transformations\n","transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","# 4. Define Image Directory Paths\n","train_img_dir = \"/content/drive/MyDrive/Colab_Notebooks/dataset/train/\"\n","test_img_dir = \"/content/drive/MyDrive/Colab_Notebooks/dataset/test/\"\n","\n","# 5. Create Datasets and Dataloaders\n","train_dataset = CustomImageDataset(train_df, train_img_dir, transform=transform)\n","val_dataset = CustomImageDataset(val_df, train_img_dir, transform=transform)  # Same dir if validation images are in `train`\n","test_dataset = CustomImageDataset(test, test_img_dir, transform=transform, is_test=True)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n","\n","# 6. Model Setup\n","num_classes = len(train[\"label\"].unique())\n","model = models.resnet50(pretrained=True)\n","model.fc = nn.Linear(model.fc.in_features, num_classes)  # Adjusting last layer\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# 7. Loss Function, Optimizer, and Scheduler\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2154752,"status":"ok","timestamp":1731880039230,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"BbAEmm2J0sSV","outputId":"6b6cd92b-532b-41c1-8dc1-8e9c31c76b49"},"outputs":[{"name":"stdout","output_type":"stream","text":["Start training...\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5 - Training: 100%|██████████| 206/206 [22:31<00:00,  6.56s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Training Loss: 1.0677, Training Accuracy: 0.6251\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5 - Validation: 100%|██████████| 52/52 [05:30<00:00,  6.35s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Validation Loss: 0.9026, Validation Accuracy: 0.7072\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5 - Training: 100%|██████████| 206/206 [01:50<00:00,  1.86it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Training Loss: 0.6925, Training Accuracy: 0.7675\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5 - Validation: 100%|██████████| 52/52 [00:22<00:00,  2.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Validation Loss: 0.6129, Validation Accuracy: 0.7934\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5 - Training: 100%|██████████| 206/206 [01:44<00:00,  1.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Training Loss: 0.5417, Training Accuracy: 0.8136\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5 - Validation: 100%|██████████| 52/52 [00:24<00:00,  2.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Validation Loss: 0.5776, Validation Accuracy: 0.7983\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5 - Training: 100%|██████████| 206/206 [01:26<00:00,  2.37it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Training Loss: 0.4309, Training Accuracy: 0.8532\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5 - Validation: 100%|██████████| 52/52 [00:20<00:00,  2.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Validation Loss: 0.6169, Validation Accuracy: 0.7934\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5 - Training: 100%|██████████| 206/206 [01:24<00:00,  2.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Training Loss: 0.3343, Training Accuracy: 0.8847\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5 - Validation: 100%|██████████| 52/52 [00:18<00:00,  2.77it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Validation Loss: 0.5033, Validation Accuracy: 0.8323\n","Training completed.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Initialize GradScaler with updated syntax\n","scaler = GradScaler()\n","\n","num_epochs = 5  # Set number of epochs\n","\n","# Initialize lists to store metrics for each epoch\n","train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n","\n","print(\"Start training...\")\n","\n","for epoch in range(num_epochs):\n","    # Training phase\n","    model.train()\n","    running_loss, correct, total = 0.0, 0, 0\n","    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        with autocast(device_type=device.type):\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        running_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs, 1)\n","        correct += (predicted == labels).sum().item()\n","        total += labels.size(0)\n","\n","    # Calculate accuracy and loss for the training epoch\n","    train_loss = running_loss / total\n","    train_accuracy = correct / total\n","    train_losses.append(train_loss)\n","    train_accuracies.append(train_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n","\n","    # Validation phase\n","    model.eval()\n","    val_running_loss, val_correct, val_total = 0.0, 0, 0\n","    with torch.no_grad():\n","        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            val_running_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs, 1)\n","            val_correct += (predicted == labels).sum().item()\n","            val_total += labels.size(0)\n","\n","    # Calculate accuracy and loss for the validation epoch\n","    val_loss = val_running_loss / val_total\n","    val_accuracy = val_correct / val_total\n","    val_losses.append(val_loss)\n","    val_accuracies.append(val_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n","\n","    # Step the learning rate scheduler\n","    scheduler.step()\n","\n","    # Save model if it improves\n","    if val_accuracy > max(val_accuracies, default=0):\n","        torch.save(model.state_dict(), f\"saved_models/sports_best_model.pth\")\n","        print(\"Model saved!\")\n","\n","# End of training\n","print(\"Training completed.\")"]},{"cell_type":"markdown","metadata":{"id":"Hg66Rpx3pbmq"},"source":["Epoch [5/5], Training Loss: 0.3478, Training Accuracy: 0.8865\n"]},{"cell_type":"markdown","metadata":{"id":"nvCQhqfBI2SJ"},"source":["## VGG"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":569379,"status":"ok","timestamp":1731880812939,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"yzO67DiapXms","outputId":"8df56b3e-ca20-4d69-db46-4ab8937872c5"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n","100%|██████████| 528M/528M [00:07<00:00, 71.5MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Start training with VGG16...\n"]},{"name":"stderr","output_type":"stream","text":["\rEpoch 1/5 - Training:   0%|          | 0/206 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","Epoch 1/5 - Training: 100%|██████████| 206/206 [01:25<00:00,  2.40it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Training Loss: 1.9168, Training Accuracy: 0.2059\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5 - Validation: 100%|██████████| 52/52 [00:19<00:00,  2.72it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Validation Loss: 1.7993, Validation Accuracy: 0.2254\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5 - Training: 100%|██████████| 206/206 [01:25<00:00,  2.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Training Loss: 1.6814, Training Accuracy: 0.3027\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5 - Validation: 100%|██████████| 52/52 [00:19<00:00,  2.72it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Validation Loss: 1.5642, Validation Accuracy: 0.3761\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5 - Training: 100%|██████████| 206/206 [01:25<00:00,  2.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Training Loss: 1.5843, Training Accuracy: 0.3641\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5 - Validation: 100%|██████████| 52/52 [00:22<00:00,  2.32it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Validation Loss: 1.5594, Validation Accuracy: 0.3937\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5 - Training: 100%|██████████| 206/206 [01:39<00:00,  2.07it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Training Loss: 1.5266, Training Accuracy: 0.3867\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5 - Validation: 100%|██████████| 52/52 [00:21<00:00,  2.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Validation Loss: 1.4173, Validation Accuracy: 0.4277\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5 - Training: 100%|██████████| 206/206 [01:39<00:00,  2.07it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Training Loss: 1.4185, Training Accuracy: 0.4525\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5 - Validation: 100%|██████████| 52/52 [00:20<00:00,  2.53it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Validation Loss: 1.3322, Validation Accuracy: 0.5049\n","Training with VGG16 completed.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# VGG\n","\n","num_classes = len(train[\"label\"].unique())\n","\n","# Load VGG16 with pre-trained weights and modify the classifier layer\n","model = models.vgg16(pretrained=True)\n","model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)  # Adjust the final layer\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# 7. Define Loss Function, Optimizer, and Scheduler\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","\n","# Initialize GradScaler for mixed precision training\n","scaler = GradScaler()\n","\n","num_epochs = 5  # Set the number of epochs\n","train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n","\n","print(\"Start training with VGG16...\")\n","\n","# 8. Training Loop\n","for epoch in range(num_epochs):\n","    # Training phase\n","    model.train()\n","    running_loss, correct, total = 0.0, 0, 0\n","    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        with autocast(device_type=device.type):\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        running_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs, 1)\n","        correct += (predicted == labels).sum().item()\n","        total += labels.size(0)\n","\n","    train_loss = running_loss / total\n","    train_accuracy = correct / total\n","    train_losses.append(train_loss)\n","    train_accuracies.append(train_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n","\n","    # Validation phase\n","    model.eval()\n","    val_running_loss, val_correct, val_total = 0.0, 0, 0\n","    with torch.no_grad():\n","        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            val_running_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs, 1)\n","            val_correct += (predicted == labels).sum().item()\n","            val_total += labels.size(0)\n","\n","    val_loss = val_running_loss / val_total\n","    val_accuracy = val_correct / val_total\n","    val_losses.append(val_loss)\n","    val_accuracies.append(val_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n","\n","    # Step the learning rate scheduler\n","    scheduler.step()\n","\n","    # Save model if it improves\n","    if val_accuracy > max(val_accuracies, default=0):\n","        torch.save(model.state_dict(), f\"saved_models/sports_best_vgg16_model.pth\")\n","        print(\"Model saved!\")\n","\n","print(\"Training with VGG16 completed.\")"]},{"cell_type":"markdown","metadata":{"id":"oNFbW1VWJLqM"},"source":["## GoogleNet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":550006,"status":"ok","timestamp":1731881397531,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"Xom_qLVhqg4E","outputId":"d0f5c9e3-51d8-4015-9681-d4c83046128f"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n","100%|██████████| 49.7M/49.7M [00:00<00:00, 98.0MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Start training with GoogLeNet...\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5 - Training: 100%|██████████| 206/206 [01:45<00:00,  1.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Training Loss: 0.6411, Training Accuracy: 0.7856\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5 - Validation: 100%|██████████| 52/52 [00:20<00:00,  2.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Validation Loss: 0.6092, Validation Accuracy: 0.7989\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5 - Training: 100%|██████████| 206/206 [01:36<00:00,  2.14it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Training Loss: 0.3414, Training Accuracy: 0.8865\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5 - Validation: 100%|██████████| 52/52 [00:22<00:00,  2.35it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Validation Loss: 0.5052, Validation Accuracy: 0.8372\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5 - Training: 100%|██████████| 206/206 [01:25<00:00,  2.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Training Loss: 0.2751, Training Accuracy: 0.9067\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5 - Validation: 100%|██████████| 52/52 [00:23<00:00,  2.21it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Validation Loss: 0.4796, Validation Accuracy: 0.8524\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5 - Training: 100%|██████████| 206/206 [01:19<00:00,  2.59it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Training Loss: 0.2029, Training Accuracy: 0.9339\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5 - Validation: 100%|██████████| 52/52 [00:17<00:00,  2.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Validation Loss: 0.3192, Validation Accuracy: 0.8870\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5 - Training: 100%|██████████| 206/206 [01:20<00:00,  2.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Training Loss: 0.1304, Training Accuracy: 0.9576\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5 - Validation: 100%|██████████| 52/52 [00:17<00:00,  2.91it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Validation Loss: 0.3783, Validation Accuracy: 0.8791\n","Training with GoogLeNet completed.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["num_classes = len(train[\"label\"].unique())\n","\n","# Load GoogLeNet with pre-trained weights and modify the final layer\n","model = models.googlenet(pretrained=True)\n","model.fc = nn.Linear(model.fc.in_features, num_classes)  # Adjust final fully connected layer\n","\n","# Move model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# Define loss function, optimizer, and scheduler\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","scaler = GradScaler()  # Mixed precision training\n","\n","# Training loop remains the same as in your existing code\n","num_epochs = 5\n","train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n","\n","print(\"Start training with GoogLeNet...\")\n","\n","for epoch in range(num_epochs):\n","    # Training phase\n","    model.train()\n","    running_loss, correct, total = 0.0, 0, 0\n","    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        with autocast(device_type=device.type):\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        running_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs, 1)\n","        correct += (predicted == labels).sum().item()\n","        total += labels.size(0)\n","\n","    train_loss = running_loss / total\n","    train_accuracy = correct / total\n","    train_losses.append(train_loss)\n","    train_accuracies.append(train_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n","\n","    # Validation phase\n","    model.eval()\n","    val_running_loss, val_correct, val_total = 0.0, 0, 0\n","    with torch.no_grad():\n","        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            val_running_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs, 1)\n","            val_correct += (predicted == labels).sum().item()\n","            val_total += labels.size(0)\n","\n","    val_loss = val_running_loss / val_total\n","    val_accuracy = val_correct / val_total\n","    val_losses.append(val_loss)\n","    val_accuracies.append(val_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n","\n","    # Step the learning rate scheduler\n","    scheduler.step()\n","\n","    # Save model if it improves\n","    if val_accuracy > max(val_accuracies, default=0):\n","        torch.save(model.state_dict(), f\"saved_models/sports_best_googlenet_model.pth\")\n","        print(\"Model saved!\")\n","\n","print(\"Training with GoogLeNet completed.\")"]},{"cell_type":"markdown","metadata":{"id":"zoPTVfsPIvw0"},"source":["## AlexNet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":459103,"status":"ok","timestamp":1731881856628,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"VrdTkc3pqg7j","outputId":"2c5ce670-a0c3-46bc-d094-d2d12ef5e32d"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n","100%|██████████| 233M/233M [00:01<00:00, 176MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Start training with AlexNet...\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5 - Training: 100%|██████████| 206/206 [01:13<00:00,  2.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Training Loss: 1.9402, Training Accuracy: 0.1924\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5 - Validation: 100%|██████████| 52/52 [00:17<00:00,  3.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Validation Loss: 1.8975, Validation Accuracy: 0.1701\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5 - Training: 100%|██████████| 206/206 [01:15<00:00,  2.71it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Training Loss: 1.8906, Training Accuracy: 0.1778\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5 - Validation: 100%|██████████| 52/52 [00:17<00:00,  3.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Validation Loss: 1.8850, Validation Accuracy: 0.1847\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5 - Training: 100%|██████████| 206/206 [01:13<00:00,  2.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Training Loss: 1.8879, Training Accuracy: 0.1814\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5 - Validation: 100%|██████████| 52/52 [00:17<00:00,  3.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Validation Loss: 1.8861, Validation Accuracy: 0.1847\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5 - Training: 100%|██████████| 206/206 [01:13<00:00,  2.80it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Training Loss: 1.8897, Training Accuracy: 0.1833\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5 - Validation: 100%|██████████| 52/52 [00:17<00:00,  2.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Validation Loss: 1.8871, Validation Accuracy: 0.1744\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5 - Training: 100%|██████████| 206/206 [01:13<00:00,  2.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Training Loss: 1.8889, Training Accuracy: 0.1816\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5 - Validation: 100%|██████████| 52/52 [00:17<00:00,  3.00it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Validation Loss: 1.8870, Validation Accuracy: 0.1847\n","Training with AlexNet completed.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# AlexNet\n","\n","# Set the number of classes for the final layer\n","num_classes = len(train[\"label\"].unique())\n","\n","# Load AlexNet with pre-trained weights and adjust the classifier for the number of classes\n","model = models.alexnet(pretrained=True)\n","model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)  # Modify final fully connected layer\n","\n","# Move model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# Define loss function, optimizer, and scheduler\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","scaler = GradScaler()  # For mixed precision training\n","\n","# Initialize lists to store metrics\n","num_epochs = 5\n","train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n","\n","print(\"Start training with AlexNet...\")\n","\n","for epoch in range(num_epochs):\n","    # Training phase\n","    model.train()\n","    running_loss, correct, total = 0.0, 0, 0\n","    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        with autocast(device_type=device.type):\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        running_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs, 1)\n","        correct += (predicted == labels).sum().item()\n","        total += labels.size(0)\n","\n","    # Calculate accuracy and loss for the training epoch\n","    train_loss = running_loss / total\n","    train_accuracy = correct / total\n","    train_losses.append(train_loss)\n","    train_accuracies.append(train_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n","\n","    # Validation phase\n","    model.eval()\n","    val_running_loss, val_correct, val_total = 0.0, 0, 0\n","    with torch.no_grad():\n","        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            val_running_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs, 1)\n","            val_correct += (predicted == labels).sum().item()\n","            val_total += labels.size(0)\n","\n","    val_loss = val_running_loss / val_total\n","    val_accuracy = val_correct / val_total\n","    val_losses.append(val_loss)\n","    val_accuracies.append(val_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n","\n","    # Step the learning rate scheduler\n","    scheduler.step()\n","\n","    # Save model if it improves\n","    if val_accuracy > max(val_accuracies, default=0):\n","        torch.save(model.state_dict(), f\"saved_models/sports_best_alexnet_model.pth\")\n","        print(\"Model saved!\")\n","\n","print(\"Training with AlexNet completed.\")"]},{"cell_type":"markdown","metadata":{"id":"RyFb53Ko3_cd"},"source":["Epoch [5/5], Training Loss: 1.8894, Training Accuracy: 0.1887 -> AlexNet  \n","Epoch [5/5], Training Loss: 0.1740, Training Accuracy: 0.9418-> googlenet  \n","Epoch [5/5], Training Loss: 1.1477, Training Accuracy: 0.5821 -> VGG16  \n","Epoch [5/5], Training Loss: 0.3478, Training Accuracy: 0.8800 -> Resnet50  \n","\n","The dataset is probably very high in variability of features, moderately to greatly large in size with a great number of classes, and high-resolution images. The better performance by GoogLeNet and ResNet50 hints at complex and subtle patterns within the dataset that simpler models like AlexNet can't match.  \n","\n","The dataset size is probably moderate to large: usually, the deeper models, like GoogLeNet and ResNet50, perform better when they have more data, which improves when using pre-trained weights. Similarly, the number of classes is probably big because, in this case, models like GoogLeNet handle the diversity among classes well, whereas AlexNet usually suffers in the multi-class environment.  \n","\n","Finally, the dataset most likely contains high-resolution images (224x224 pixels or larger), as GoogLeNet and ResNet50 rely on detailed spatial information to distinguish complex features; this resolution allows deeper models to capture class-specific details—suggesting that GoogLeNet and ResNet50 would really be among the best choices for this dataset.  \n","\n"]},{"cell_type":"markdown","metadata":{"id":"BiQCHGLHIJyg"},"source":["# Upsample"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3039,"status":"ok","timestamp":1731991200037,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"ZBoPMO3dNf0b","outputId":"3e605170-56bd-470a-c72b-fb3cabc07731"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (10892, 2)\n","Test shape: (2056, 1)\n"]}],"source":["# Define file paths\n","train_csv = \"/content/drive/MyDrive/Colab_Notebooks/dataset/train_upsample.csv\"\n","test_csv = \"/content/drive/MyDrive/Colab_Notebooks/dataset/test.csv\"\n","\n","# Load CSV files\n","train = pd.read_csv(train_csv, usecols=[\"image_ID\", \"label\"])\n","test = pd.read_csv(test_csv, usecols=[\"image_ID\"])\n","\n","# Display shapes of train and test datasets\n","print(\"Train shape:\", train.shape)\n","print(\"Test shape:\", test.shape)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":3,"status":"ok","timestamp":1731991205447,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"ChA5FxKOqhF-","outputId":"321e3821-a149-40d1-9a8f-09da01e89bf9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Unique classes: ['Swimming' 'Cricket' 'Soccer' 'Wrestling' 'Tennis' 'Karate' 'Badminton']\n","Number of unique classes: 7\n"]}],"source":["image_to_label_map = dict(zip(train[\"image_ID\"].values, train[\"label\"].values))\n","\n","unique_classes = train[\"label\"].unique()\n","print(\"Unique classes:\", unique_classes)\n","print(\"Number of unique classes:\", len(unique_classes))"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":466},"executionInfo":{"elapsed":2191,"status":"ok","timestamp":1731991203719,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"mdGgaFEmIXlc","outputId":"e06c9c8b-1776-48e9-f95b-48ec218cd2d8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<Axes: xlabel='label', ylabel='count'>"]},"metadata":{},"execution_count":5},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}],"source":["import seaborn as sns\n","\n","sns.countplot(data=train, x=\"label\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":411,"status":"ok","timestamp":1731991208937,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"vGJBtlzGIbw7","outputId":"0bb7e601-d519-4f39-afcb-a53bd7dac84f"},"outputs":[{"output_type":"stream","name":"stdout","text":["label\n","Swimming     1556\n","Cricket      1556\n","Soccer       1556\n","Wrestling    1556\n","Tennis       1556\n","Karate       1556\n","Badminton    1556\n","Name: count, dtype: int64\n"]}],"source":["label_counts = train[\"label\"].value_counts()\n","print(label_counts)"]},{"cell_type":"markdown","metadata":{"id":"RXpZUGzlJ0NJ"},"source":["## Resnet50 - Upsample"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"OXFGx4XmIe4K","executionInfo":{"status":"ok","timestamp":1731991218380,"user_tz":300,"elapsed":8135,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"}}},"outputs":[],"source":["from PIL import Image\n","import os\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import models, transforms\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.model_selection import train_test_split\n","from torch.cuda.amp import GradScaler, autocast\n","from torch.amp import GradScaler, autocast\n","from tqdm import tqdm\n","\n","# Resnet50\n","# Dataset class for loading images and labels\n","class CustomImageDataset(Dataset):\n","    def __init__(self, dataframe, img_dir, transform=None, is_test=False):\n","        self.dataframe = dataframe\n","        self.img_dir = img_dir\n","        self.transform = transform\n","        self.is_test = is_test\n","\n","    def __len__(self):\n","        return len(self.dataframe)\n","\n","    def __getitem__(self, idx):\n","        img_name = os.path.join(self.img_dir, self.dataframe.iloc[idx, 0])\n","        image = Image.open(img_name).convert(\"RGB\")\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        if self.is_test or \"label\" not in self.dataframe.columns:\n","            return image  # No label available for test data\n","        label = torch.tensor(self.dataframe.iloc[idx, 1], dtype=torch.long)\n","        return image, label\n"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":944,"status":"ok","timestamp":1731991219321,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"},"user_tz":300},"id":"57kl43KvIihv","outputId":"b93f84f2-6bf6-44a4-a6e6-45f65b5448c9"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100%|██████████| 97.8M/97.8M [00:00<00:00, 211MB/s]\n"]}],"source":["# 2. Split Data into Train and Validation Sets\n","train['label'] = pd.Categorical(train['label']).codes\n","train_df, val_df = train_test_split(train, test_size=0.2, random_state=42)  # 80-20 split\n","\n","# 3. Define Image Transformations\n","transform = transforms.Compose([\n","    transforms.Resize(256),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","])\n","\n","# 4. Define Image Directory Paths\n","train_img_dir = \"/content/drive/MyDrive/Colab_Notebooks/dataset/upsampled/\"\n","test_img_dir = \"/content/drive/MyDrive/Colab_Notebooks/dataset/test/\"\n","\n","# 5. Create Datasets and Dataloaders\n","train_dataset = CustomImageDataset(train_df, train_img_dir, transform=transform)\n","val_dataset = CustomImageDataset(val_df, train_img_dir, transform=transform)  # Same dir if validation images are in `train`\n","test_dataset = CustomImageDataset(test, test_img_dir, transform=transform, is_test=True)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n","val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n","\n","# 6. Model Setup\n","num_classes = len(train[\"label\"].unique())\n","model = models.resnet50(pretrained=True)\n","model.fc = nn.Linear(model.fc.in_features, num_classes)  # Adjusting last layer\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# 7. Loss Function, Optimizer, and Scheduler\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"E0PgG1YpIkzn","outputId":"ce9a9793-2d0f-4f42-8109-653c4efaf82b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Start training...\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5 - Training: 100%|██████████| 273/273 [31:51<00:00,  7.00s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Training Loss: 1.1491, Training Accuracy: 0.6068\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5 - Validation: 100%|██████████| 69/69 [07:52<00:00,  6.85s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Validation Loss: 1.0207, Validation Accuracy: 0.6696\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5 - Training: 100%|██████████| 273/273 [00:30<00:00,  9.01it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Training Loss: 0.8098, Training Accuracy: 0.7248\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5 - Validation: 100%|██████████| 69/69 [00:07<00:00,  9.42it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Validation Loss: 0.7773, Validation Accuracy: 0.7260\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5 - Training: 100%|██████████| 273/273 [00:30<00:00,  9.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Training Loss: 0.6512, Training Accuracy: 0.7800\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5 - Validation: 100%|██████████| 69/69 [00:07<00:00,  9.61it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Validation Loss: 0.5958, Validation Accuracy: 0.8063\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5 - Training: 100%|██████████| 273/273 [00:30<00:00,  8.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Training Loss: 0.5168, Training Accuracy: 0.8234\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5 - Validation: 100%|██████████| 69/69 [00:07<00:00,  9.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Validation Loss: 0.5531, Validation Accuracy: 0.8219\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5 - Training: 100%|██████████| 273/273 [00:29<00:00,  9.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Training Loss: 0.4076, Training Accuracy: 0.8608\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5 - Validation: 100%|██████████| 69/69 [00:07<00:00,  9.48it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Validation Loss: 0.6456, Validation Accuracy: 0.8036\n","Training completed.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# Initialize GradScaler with updated syntax\n","scaler = GradScaler()\n","\n","num_epochs = 5  # Set number of epochs\n","\n","# Initialize lists to store metrics for each epoch\n","train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n","\n","print(\"Start training...\")\n","\n","for epoch in range(num_epochs):\n","    # Training phase\n","    model.train()\n","    running_loss, correct, total = 0.0, 0, 0\n","    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        with autocast(device_type=device.type):\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        running_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs, 1)\n","        correct += (predicted == labels).sum().item()\n","        total += labels.size(0)\n","\n","    # Calculate accuracy and loss for the training epoch\n","    train_loss = running_loss / total\n","    train_accuracy = correct / total\n","    train_losses.append(train_loss)\n","    train_accuracies.append(train_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n","\n","    # Validation phase\n","    model.eval()\n","    val_running_loss, val_correct, val_total = 0.0, 0, 0\n","    with torch.no_grad():\n","        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            val_running_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs, 1)\n","            val_correct += (predicted == labels).sum().item()\n","            val_total += labels.size(0)\n","\n","    # Calculate accuracy and loss for the validation epoch\n","    val_loss = val_running_loss / val_total\n","    val_accuracy = val_correct / val_total\n","    val_losses.append(val_loss)\n","    val_accuracies.append(val_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n","\n","    # Step the learning rate scheduler\n","    scheduler.step()\n","\n","    # Save model if it improves\n","    if val_accuracy > max(val_accuracies, default=0):\n","        torch.save(model.state_dict(), f\"saved_models/sports_best_model.pth\")\n","        print(\"Model saved!\")\n","\n","# End of training\n","print(\"Training completed.\")"]},{"cell_type":"markdown","metadata":{"id":"IQw4m1h-JR-M"},"source":["## VGG - Upsample"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"p8zdektOInC8","outputId":"f3fd2b49-e19e-464b-fb7f-f41108b33b81"},"outputs":[{"name":"stdout","output_type":"stream","text":["Start training with VGG16...\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5 - Training: 100%|██████████| 273/273 [00:29<00:00,  9.26it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Training Loss: 1.7784, Training Accuracy: 0.2691\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5 - Validation: 100%|██████████| 69/69 [00:07<00:00,  9.56it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Validation Loss: 1.5090, Validation Accuracy: 0.3786\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5 - Training: 100%|██████████| 273/273 [00:29<00:00,  9.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Training Loss: 1.6377, Training Accuracy: 0.3344\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5 - Validation: 100%|██████████| 69/69 [00:07<00:00,  9.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Validation Loss: 1.5472, Validation Accuracy: 0.3786\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5 - Training: 100%|██████████| 273/273 [00:29<00:00,  9.32it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Training Loss: 1.5480, Training Accuracy: 0.3917\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5 - Validation: 100%|██████████| 69/69 [00:07<00:00,  9.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Validation Loss: 1.5035, Validation Accuracy: 0.4493\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5 - Training: 100%|██████████| 273/273 [00:29<00:00,  9.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Training Loss: 1.4884, Training Accuracy: 0.4210\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5 - Validation: 100%|██████████| 69/69 [00:07<00:00,  9.15it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Validation Loss: 1.3551, Validation Accuracy: 0.5145\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5 - Training: 100%|██████████| 273/273 [00:29<00:00,  9.31it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Training Loss: 1.4080, Training Accuracy: 0.4694\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5 - Validation: 100%|██████████| 69/69 [00:07<00:00,  9.49it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Validation Loss: 1.3464, Validation Accuracy: 0.5145\n","Training with VGG16 completed.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# VGG\n","\n","num_classes = len(train[\"label\"].unique())\n","\n","# Load VGG16 with pre-trained weights and modify the classifier layer\n","model = models.vgg16(pretrained=True)\n","model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)  # Adjust the final layer\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# 7. Define Loss Function, Optimizer, and Scheduler\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","\n","# Initialize GradScaler for mixed precision training\n","scaler = GradScaler()\n","\n","num_epochs = 5  # Set the number of epochs\n","train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n","\n","print(\"Start training with VGG16...\")\n","\n","# 8. Training Loop\n","for epoch in range(num_epochs):\n","    # Training phase\n","    model.train()\n","    running_loss, correct, total = 0.0, 0, 0\n","    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        with autocast(device_type=device.type):\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        running_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs, 1)\n","        correct += (predicted == labels).sum().item()\n","        total += labels.size(0)\n","\n","    train_loss = running_loss / total\n","    train_accuracy = correct / total\n","    train_losses.append(train_loss)\n","    train_accuracies.append(train_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n","\n","    # Validation phase\n","    model.eval()\n","    val_running_loss, val_correct, val_total = 0.0, 0, 0\n","    with torch.no_grad():\n","        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            val_running_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs, 1)\n","            val_correct += (predicted == labels).sum().item()\n","            val_total += labels.size(0)\n","\n","    val_loss = val_running_loss / val_total\n","    val_accuracy = val_correct / val_total\n","    val_losses.append(val_loss)\n","    val_accuracies.append(val_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n","\n","    # Step the learning rate scheduler\n","    scheduler.step()\n","\n","    # Save model if it improves\n","    if val_accuracy > max(val_accuracies, default=0):\n","        torch.save(model.state_dict(), f\"saved_models/sports_best_vgg16_model.pth\")\n","        print(\"Model saved!\")\n","\n","print(\"Training with VGG16 completed.\")"]},{"cell_type":"markdown","metadata":{"id":"U7HJjH1HJVUi"},"source":["## GoogleNet - Upsample"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"5HRWVAWyIpUF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1731993668397,"user_tz":300,"elapsed":2430150,"user":{"displayName":"Zhizheng Wang","userId":"14753778185706983913"}},"outputId":"a84e241e-c483-4266-edd6-9b4f3664bbab"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/googlenet-1378be20.pth\" to /root/.cache/torch/hub/checkpoints/googlenet-1378be20.pth\n","100%|██████████| 49.7M/49.7M [00:00<00:00, 207MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Start training with GoogLeNet...\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/5 - Training: 100%|██████████| 273/273 [30:31<00:00,  6.71s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/5], Training Loss: 0.7493, Training Accuracy: 0.7414\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1/5 - Validation: 100%|██████████| 69/69 [07:26<00:00,  6.48s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/5], Validation Loss: 0.5426, Validation Accuracy: 0.8201\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/5 - Training: 100%|██████████| 273/273 [00:29<00:00,  9.13it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/5], Training Loss: 0.4634, Training Accuracy: 0.8440\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2/5 - Validation: 100%|██████████| 69/69 [00:07<00:00,  9.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [2/5], Validation Loss: 0.5095, Validation Accuracy: 0.8274\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/5 - Training: 100%|██████████| 273/273 [00:30<00:00,  8.90it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/5], Training Loss: 0.3457, Training Accuracy: 0.8853\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3/5 - Validation: 100%|██████████| 69/69 [00:07<00:00,  9.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [3/5], Validation Loss: 0.4626, Validation Accuracy: 0.8541\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/5 - Training: 100%|██████████| 273/273 [00:30<00:00,  9.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/5], Training Loss: 0.2737, Training Accuracy: 0.9073\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4/5 - Validation: 100%|██████████| 69/69 [00:07<00:00,  9.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [4/5], Validation Loss: 0.4420, Validation Accuracy: 0.8614\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/5 - Training: 100%|██████████| 273/273 [00:30<00:00,  8.99it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/5], Training Loss: 0.2000, Training Accuracy: 0.9348\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 5/5 - Validation: 100%|██████████| 69/69 [00:07<00:00,  9.16it/s]"]},{"output_type":"stream","name":"stdout","text":["Epoch [5/5], Validation Loss: 0.5509, Validation Accuracy: 0.8261\n","Training with GoogLeNet completed.\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["num_classes = len(train[\"label\"].unique())\n","\n","# Load GoogLeNet with pre-trained weights and modify the final layer\n","model = models.googlenet(pretrained=True)\n","model.fc = nn.Linear(model.fc.in_features, num_classes)  # Adjust final fully connected layer\n","\n","# Move model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# Define loss function, optimizer, and scheduler\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","scaler = GradScaler()  # Mixed precision training\n","\n","# Training loop remains the same as in your existing code\n","num_epochs = 5\n","train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n","\n","print(\"Start training with GoogLeNet...\")\n","\n","for epoch in range(num_epochs):\n","    # Training phase\n","    model.train()\n","    running_loss, correct, total = 0.0, 0, 0\n","    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        with autocast(device_type=device.type):\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        running_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs, 1)\n","        correct += (predicted == labels).sum().item()\n","        total += labels.size(0)\n","\n","    train_loss = running_loss / total\n","    train_accuracy = correct / total\n","    train_losses.append(train_loss)\n","    train_accuracies.append(train_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n","\n","    # Validation phase\n","    model.eval()\n","    val_running_loss, val_correct, val_total = 0.0, 0, 0\n","    with torch.no_grad():\n","        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            val_running_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs, 1)\n","            val_correct += (predicted == labels).sum().item()\n","            val_total += labels.size(0)\n","\n","    val_loss = val_running_loss / val_total\n","    val_accuracy = val_correct / val_total\n","    val_losses.append(val_loss)\n","    val_accuracies.append(val_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n","\n","    # Step the learning rate scheduler\n","    scheduler.step()\n","\n","    # Save model if it improves\n","    if val_accuracy > max(val_accuracies, default=0):\n","        torch.save(model.state_dict(), f\"saved_models/sports_best_googlenet_model.pth\")\n","        print(\"Model saved!\")\n","\n","print(\"Training with GoogLeNet completed.\")"]},{"cell_type":"markdown","source":["## AlexNet"],"metadata":{"id":"El9SzqWYtwpZ"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"jETuVyybIrkU","outputId":"41042ea3-71a8-4590-a7ce-ae6890d3c14a"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n","100%|██████████| 233M/233M [00:01<00:00, 220MB/s]\n"]},{"name":"stdout","output_type":"stream","text":["Start training with AlexNet...\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5 - Training: 100%|██████████| 273/273 [00:29<00:00,  9.30it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Training Loss: 1.9622, Training Accuracy: 0.1513\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1/5 - Validation: 100%|██████████| 69/69 [00:07<00:00,  9.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/5], Validation Loss: 1.9460, Validation Accuracy: 0.1459\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5 - Training: 100%|██████████| 273/273 [00:28<00:00,  9.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Training Loss: 1.9467, Training Accuracy: 0.1440\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2/5 - Validation: 100%|██████████| 69/69 [00:07<00:00,  9.81it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/5], Validation Loss: 1.9470, Validation Accuracy: 0.1459\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5 - Training: 100%|██████████| 273/273 [00:29<00:00,  9.24it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Training Loss: 1.9474, Training Accuracy: 0.1458\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3/5 - Validation: 100%|██████████| 69/69 [00:07<00:00,  9.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/5], Validation Loss: 1.9461, Validation Accuracy: 0.1436\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5 - Training: 100%|██████████| 273/273 [00:29<00:00,  9.39it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Training Loss: 1.9467, Training Accuracy: 0.1456\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4/5 - Validation: 100%|██████████| 69/69 [00:07<00:00,  9.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/5], Validation Loss: 1.9502, Validation Accuracy: 0.1441\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5 - Training: 100%|██████████| 273/273 [00:28<00:00,  9.62it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Training Loss: 1.9471, Training Accuracy: 0.1414\n"]},{"name":"stderr","output_type":"stream","text":["Epoch 5/5 - Validation: 100%|██████████| 69/69 [00:07<00:00,  9.71it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/5], Validation Loss: 1.9506, Validation Accuracy: 0.1335\n","Training with AlexNet completed.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["# AlexNet\n","\n","# Set the number of classes for the final layer\n","num_classes = len(train[\"label\"].unique())\n","\n","# Load AlexNet with pre-trained weights and adjust the classifier for the number of classes\n","model = models.alexnet(pretrained=True)\n","model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)  # Modify final fully connected layer\n","\n","# Move model to GPU if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = model.to(device)\n","\n","# Define loss function, optimizer, and scheduler\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","scaler = GradScaler()  # For mixed precision training\n","\n","# Initialize lists to store metrics\n","num_epochs = 5\n","train_losses, val_losses, train_accuracies, val_accuracies = [], [], [], []\n","\n","print(\"Start training with AlexNet...\")\n","\n","for epoch in range(num_epochs):\n","    # Training phase\n","    model.train()\n","    running_loss, correct, total = 0.0, 0, 0\n","    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        with autocast(device_type=device.type):\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","        scaler.scale(loss).backward()\n","        scaler.step(optimizer)\n","        scaler.update()\n","\n","        running_loss += loss.item() * images.size(0)\n","        _, predicted = torch.max(outputs, 1)\n","        correct += (predicted == labels).sum().item()\n","        total += labels.size(0)\n","\n","    # Calculate accuracy and loss for the training epoch\n","    train_loss = running_loss / total\n","    train_accuracy = correct / total\n","    train_losses.append(train_loss)\n","    train_accuracies.append(train_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {train_loss:.4f}, Training Accuracy: {train_accuracy:.4f}\")\n","\n","    # Validation phase\n","    model.eval()\n","    val_running_loss, val_correct, val_total = 0.0, 0, 0\n","    with torch.no_grad():\n","        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            val_running_loss += loss.item() * images.size(0)\n","            _, predicted = torch.max(outputs, 1)\n","            val_correct += (predicted == labels).sum().item()\n","            val_total += labels.size(0)\n","\n","    val_loss = val_running_loss / val_total\n","    val_accuracy = val_correct / val_total\n","    val_losses.append(val_loss)\n","    val_accuracies.append(val_accuracy)\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n","\n","    # Step the learning rate scheduler\n","    scheduler.step()\n","\n","    # Save model if it improves\n","    if val_accuracy > max(val_accuracies, default=0):\n","        torch.save(model.state_dict(), f\"saved_models/sports_best_alexnet_model.pth\")\n","        print(\"Model saved!\")\n","\n","print(\"Training with AlexNet completed.\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}